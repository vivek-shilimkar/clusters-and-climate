<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mlops on Clusters and Climate</title>
    <link>https://clustersandclimate.com/tags/mlops/</link>
    <description>Recent content in Mlops on Clusters and Climate</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 11:00:00 +0530</lastBuildDate>
    <atom:link href="https://clustersandclimate.com/tags/mlops/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Install ML workloads with Rancher â€” Quick Guide</title>
      <link>https://clustersandclimate.com/technology/install-ml-with-rancher-excerpt/</link>
      <pubDate>Fri, 10 Oct 2025 11:00:00 +0530</pubDate>
      <guid>https://clustersandclimate.com/technology/install-ml-with-rancher-excerpt/</guid>
      <description>Rancher makes it straightforward to manage clusters and run ML workloads across edge and cloud. This quick guide shows the fast path: create a cluster (or use k3s locally), add nodepools for GPU and spot instances, install KServe, and deploy a small demo model.</description>
    </item>
    <item>
      <title>Install ML workloads with Rancher: from cluster to inference</title>
      <link>https://clustersandclimate.com/technology/install-ml-with-rancher/</link>
      <pubDate>Fri, 10 Oct 2025 10:00:00 +0530</pubDate>
      <guid>https://clustersandclimate.com/technology/install-ml-with-rancher/</guid>
      <description>This guide walks through a practical path to run ML workloads using Rancher as the control plane. It covers provisioning clusters, creating nodepools for GPU and spot/low-priority instances, installing an ML inference stack (KServe), and deploying a minimal demo model.</description>
    </item>
  </channel>
</rss>
